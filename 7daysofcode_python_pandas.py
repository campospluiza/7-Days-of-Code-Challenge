# -*- coding: utf-8 -*-
"""7daysofcode_python_pandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ceuzi8w1uqvYISyHiO7-VrJ6FQZ4Jwz6

On day 1 of the challenge, I started by importing all the data. As the library loan data was in different files, I first unified all of them into the "Loan Data" dataframe. Then, I merged this with the Apache file. Finally, I performed a data cleaning of duplicate values.

En el primer día del desafío, comencé importando todos los datos. Como los datos de préstamo de la biblioteca estaban en diferentes archivos, primero los unifiqué en el marco de datos: "Datos de préstamo". Luego, unifiqué esto con el archivo Apache. Finalmente, realicé una limpieza de los datos duplicados.
"""

import pandas as pd

data2010_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20101.csv?raw=true')
data2010_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20102.csv?raw=true')
data2011_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20111.csv?raw=true')
data2011_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20112.csv?raw=true')
data2012_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20121.csv?raw=true')
data2012_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20122.csv?raw=true')
data2013_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20131.csv?raw=true')
data2013_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20132.csv?raw=true')
data2014_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20141.csv?raw=true')
data2014_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20142.csv?raw=true')
data2015_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20151.csv?raw=true')
data2015_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20152.csv?raw=true')
data2016_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20161.csv?raw=true')
data2016_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20162.csv?raw=true')
data2017_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20171.csv?raw=true')
data2017_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20172.csv?raw=true')
data2018_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20181.csv?raw=true')
data2018_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20182.csv?raw=true')
data2019_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20191.csv?raw=true')
data2019_2 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20192.csv?raw=true')
data2020_1 = pd.read_csv('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/blob/main/Dia_1-Importando_dados/Datasets/dados_emprestimos/emprestimos-20201.csv?raw=true')

df_loan_library = pd.concat([data2010_1, data2010_2, data2011_1, data2011_2, data2012_1, data2012_2, data2013_1, data2013_2, data2014_1, data2014_2, data2015_1, data2015_2, data2016_1, 
                             data2016_2, data2017_1, data2017_2, data2018_1, data2018_2, data2019_1, data2019_2, data2020_1])

type(df_loan_library)

df_loan_library.value_counts()

df_loan_library.drop_duplicates()

df_loan_library.value_counts()

data_books = pd.read_parquet('https://github.com/FranciscoFoz/7_Days_of_Code_Alura-Python-Pandas/raw/main/Dia_1-Importando_dados/Datasets/dados_exemplares.parquet')
data_books

df_data_books = pd.DataFrame(data_books)

df_loan_library = pd.DataFrame(df_loan_library)

df_final = df_loan_library.merge(df_data_books)
df_final

CDU_lista = []
for CDU in df_final['localizacao']:
  if(CDU < 100):
    CDU_lista.append('Generalidades')
  elif(CDU < 200):
    CDU_lista.append('Filosofia e psicologia')
  elif(CDU < 300):
    CDU_lista.append('Religião')
  elif(CDU < 400):
    CDU_lista.append('Ciências sociais')
  elif(CDU < 500):
    CDU_lista.append('Classe vaga')
  elif(CDU < 600):
    CDU_lista.append('Matemática e ciências naturais')
  elif(CDU < 700):
    CDU_lista.append('Ciências aplicadas')
  elif(CDU < 800):
    CDU_lista.append('Belas artes')
  elif(CDU < 900):
    CDU_lista.append('Linguagem')
  else:
    CDU_lista.append('Geografia. Biografia. História.')

  CDU_lista

df_final['CDU_lista'] = CDU

df_final = df_final.drop(columns=['registro_sistema'])

df_final['matricula_ou_siape'] = df_final['matricula_ou_siape'].astype(str)

categorias = {
    range(0, 100): 'Generalidades. Ciência e conhecimento.',
    range(100, 200): 'Filosofia e psicologia.',
    range(200, 300): 'Religião.',
    range(300, 400): 'Ciências sociais.',
    range(400, 500): 'Classe vaga. Provisoriamente não ocupada.',
    range(500, 600): 'Matemática e ciências naturais.',
    range(600, 700): 'Ciências aplicadas.',
    range(700, 800): 'Belas artes.',
    range(800, 900): 'Linguagem. Língua. Linguística.',
    range(900, 1000): 'Geografia. Biografia. História.'
}

df_final['Categoria'] = df_final['CDU_lista'].map({CDU_lista: categoria for rango, categoria in categorias.items() for CDU_lista in rango})

#On day 3 i started to extract data from the dataframe according to what was asked in the challenge

import pandas as pd
import matplotlib.pyplot as plt

df_final['data_emprestimo'] = pd.to_datetime(df_final['data_emprestimo'])

prestamos_por_ano = df_final.groupby(df_final['data_emprestimo'].dt.year)['data_emprestimo'].count()
print(prestamos_por_ano)

plt.plot(prestamos_por_ano.index, prestamos_por_ano.values)
plt.xlabel('Ano')
plt.ylabel('Quantidade de exemplares emprestados')
plt.show()

emprestimos_por_mes = df_final.groupby([df_final['data_emprestimo'].dt.month])['data_emprestimo'].count()
print(emprestimos_por_mes)

plt.plot(emprestimos_por_mes.index, emprestimos_por_mes.values)
plt.xlabel('Mês')
plt.ylabel

emprestimos_por_hora = df_final.groupby(df_final['data_emprestimo'].dt.hour)['data_emprestimo'].count()

plt.plot(emprestimos_por_hora.index, emprestimos_por_hora.values)
plt.xlabel('Hora')
plt.ylabel('Número de empréstimos')
plt.title('Evolución de empréstimos por hora')
plt.show()
